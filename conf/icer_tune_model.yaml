# @package _global_
data:
  data_dir: /mnt/home/xiziyi/Packages_Research/PhaseNet-PyTorch/dataset-all
  train: tongaml_train.h5
  test: tongaml_test.h5
  val: tongaml_val.h5
  train_trans: ["shift", "scale", "label"]
  val_trans: ["scale", "label"]
  test_trans: ["scale", "label"]

  # tuned
  stack_ratio: 0.9738217746076991
  noise_replace_ratio: 0.3210340323794437

train:
  epochs: 160

  accelerator: gpu
  strategy: ddp_find_unused_parameters_false
  use_amp: true
  use_a100: true

  distributed_devices: [0, 1, 2, 3]

  run_type: hyper_tune

visualize:
  log_val: true
  log_test: true
  log_epoch: 30
  sgram_threshold: 500
  log_test_seprate_folder: false
  log_test_seprate_folder_path: ""

hydra:
  job:
    name: tune_model
  launcher:
    timeout_min: 120
    nodes: 1
    tasks_per_node: 4
    cpus_per_task: 4
    mem_gb: 70
    gres: gpu:a100:4
    account: cmse
  sweeper:
    sampler:
      _target_: optuna.samplers.TPESampler
      seed: 123
      consider_prior: true
      prior_weight: 1.0
      consider_magic_clip: true
      consider_endpoints: false
      n_startup_trials: 10
      n_ei_candidates: 24
      multivariate: false
      warn_independent_sampling: true
    _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
    direction: minimize
    storage: null
    study_name: tune_model
    n_trials: 80
    n_jobs: 8
    params:
      model.init_features: choice(8,16,32)
      model.first_layer_repeating_cnn: range(0,6,step=1)
      model.encoder_conv_kernel_size: choice([3,3],[3,5],[5,3],[5,5])
      model.decoder_conv_kernel_size: choice([3,3],[3,5],[5,3],[5,5])
      model.encoder_decoder_depth: choice(2,3,4,5)
